- Class: meta
  Course: Exploratory_Data_Analysis
  Lesson: Dimension_Reduction
  Author: Swirl Coders
  Type: Standard
  Organization: Johns Hopkins Bloomberg School of Public Health
  Version: 2.2.0

- Class: text
  Output:  在本课中，我们将讨论主要成分分析（PCA）和奇异值分解（SVD），这是两个重要的相关降维技术。这最后需要在数据集中找到包含其本质的
    变量和子集的过程。 PCA和SVD在探索阶段和更正式的分析建模阶段都被使用。我们将关注探索阶段，并简要介绍一些基础理论

- Class: figure
  Output:  我们将从一个例子开始--一些随机数据.
  Figure: showRanMat.R
  FigureType: new

- Class: cmd_question
  Output:  这是dataMatrix，一个包含400个随机正态数字（平均值0和标准偏差1）的矩阵。我们用R函数image显示它。
    以dataMatrix作为参数运行R函数head，查看dataMatrix的构成。
  CorrectAnswer: head(dataMatrix)
  AnswerTests: omnitest(correctExpr='head(dataMatrix)')
  Hint: 在命令提示符下输入head（dataMatrix）

- Class: cmd_question
  Output:  所以我们看到dataMatrix有10列（因此有40行）的随机数。这里的图像看起来很随意。我们来看看数据如何聚类。
    使用dataMatrix作为唯一参数运行R函数heatmap。
  CorrectAnswer: heatmap(dataMatrix)
  AnswerTests: omnitest(correctExpr='heatmap(dataMatrix)')
  Hint: 在命令提示符下输入heatmap(dataMatrix)

- Class: text
  Output: 我们可以看到，即使使用heatmap提供的聚类，独立排列行（观察值）和列（变量），数据仍然看起来是随机的。

- Class: cmd_question
  Output: 我们添加一个模式到数据。我们已经把一些R代码放在了文件addPatt.R中。用单个参数“addPatt.R”运行命令myedit（确保使用引号）来查看代码。
  CorrectAnswer: myedit("addPatt.R")
  AnswerTests: omnitest(correctExpr='myedit("addPatt.R")')
  Hint: 在命令提示符下输入myedit（“addPatt.R”）。

- Class: mult_question
  Output: 看代码。矩阵的每一行都会添加一个模式吗？
  AnswerChoices:  Yes; No
  CorrectAnswer:  No
  AnswerTests: omnitest(correctVal='No')
  Hint: coinflip做什么?

- Class: mult_question
  Output: 所以一个行是否被一个模式修改是由投币决定的。添加的模式会影响受影响行中的每一列吗?
  AnswerChoices:  Yes; No
  CorrectAnswer:  No
  AnswerTests: omnitest(correctVal='No')
  Hint: 表达式rep（c（0,3），each= 5）创建长10向量（0,0,0,0,0,3,3,3,3,3），它被添加到的行由硬币翻转选择.

- Class: text
  Output: 因此，在受投掷币影响的行中，左侧5列的平均值仍为0，而右侧5列的平均值接近3

- Class: cmd_question
  Output: 现在执行这个代码，用两个参数运行R函数source。第一个是文件名（用引号）--“addPatt.R”，第二个是参数local等于TRUE
  CorrectAnswer: source("addPatt.R", local=TRUE)
  AnswerTests: omnitest(correctExpr='source("addPatt.R", local=TRUE)')
  Hint: 在命令提示符处输入source（“addPatt.R”，local = TRUE）

- Class: figure
  Output: 这是添加了模式之后更改的dataMatrix的图像。图像在矩阵的列中清晰可见。右半部分更黄或更热，表示矩阵中的值更高。
  Figure: showRanMat.R
  FigureType: new

- Class: cmd_question
  Output:  现在再次使用dataMatrix作为参数运行R函数heatmap。这将对矩阵执行分层聚类分析。
  CorrectAnswer: heatmap(dataMatrix)
  AnswerTests: omnitest(correctExpr='heatmap(dataMatrix)')
  Hint: 在命令提示符下输入heatmap(dataMatrix)。

- Class: text
  Output: 我们再次看到矩阵列中的模式。如显示屏顶部的树状图所示，这些分为2个簇，编号较低的列（1至5）和编号较高的列（6至10）。
    回想一下addPatt.R中的代码，对于由coinflip选择的行，最后5列已经添加了3行。行仍然是随机的。

- Class: figure
  Output: 现在考虑这张照片。在左边是一个类似于你刚绘制的dataMatix的热图的图像。它是hclust（）的输出图像图，
    是一个应用于dataMatrix的层次聚类函数。黄色表示比红色“更热”或更高的值。这与我们应用于数据的模式（增加一些最右边的列的值）是一致的
  Figure: showPatt.R
  FigureType: new

- Class: text
  Output: 中间显示屏显示40行（沿着x轴）的每一行的平均值。行的显示顺序与左侧热矩阵的行相同。最右边的显示屏显示10列中的每一列的平均值。
    这里的列号是沿着x轴的，列均值是沿着y的。 

- Class: text
  Output: 我们立即看到集群图像的黄色（较热的）部分与较高的行的连接，均位于图形的右上部分。同样，较高的列均值着在图形的右半部分，
    而较低的列均值在左半部分。

- Class: text
  Output: 现在我们来谈一点理论。假设你有1000个多元变量X_1，...，X_n。多变量是指每个X_i包含很多分量，即X_i =（X_ {i1}，...，X_ {im}。
    但是，这些变量（观测值）及其分量可能是相互关联的。

- Class: mult_question
  Output: 以下哪一个将是一个相互关联的变量的例子？
  AnswerChoices:  Heights and weights of members of a family; Today's weather and a butterfly's wing position; The depth of the Atlantic Ocean and what you eat for    breakfast
  CorrectAnswer:  Heights and weights of members of a family
  AnswerTests: omnitest(correctVal='Heights and weights of members of a family')
  Hint: 哪一个选择是唯一有意义的选择?

- Class: text
  Output: 作为数据科学家，我们希望找到一组不相关的多元变量，并尽可能多地解释数据的差异（或变异性）。这是一个统计方法。

- Class: text
  Output: 换句话说，我们希望找到用较少的变量（即较低的秩矩阵）创建的最佳矩阵，它解释了原始数据。这与数据压缩有关。

- Class: text
  Output: 这些问题的两个相关解决方案是主成分分析的PCA和奇异值分解。后者简单地意味着我们将观察（行）和变量（列）的矩阵X
    表示为3个其他矩阵的乘积，即X = UDV ^ t。这最后一项（V ^ t）表示矩阵V的转置。

- Class: text
  Output: 这里U和V各有正交（不相关）的列。 U的列是X的左奇异向量，V的列是X的右奇异向量。D是对角矩阵，即它不在对角线上的所有值都是0.D的对角项是X的奇异值

- Class: cmd_question
  Output:  为了说明这个想法，我们创建了一个简单的示例矩阵叫mat。现在看看
  CorrectAnswer: mat
  AnswerTests: omnitest(correctExpr='mat')
  Hint: 在命令提示符处输入mat

- Class: cmd_question
  Output:  所以mat是一个2乘3的矩阵。对我们来说幸运的是R提供了执行奇异值分解的功能。毫无疑问，这就是所谓的svd。现在用一个参数mat来调用它
  CorrectAnswer: svd(mat)
  AnswerTests: omnitest(correctExpr='svd(mat)')
  Hint: 在命令提示符下输入svd（mat）

- Class: cmd_question
  Output: 我们看到函数返回3个分量，d其中包含2个对角线元素，u是一个2×2的矩阵，v是一个3×2的矩阵。我们将对角线分量存储在一个
    对角线矩阵中diag，并且我们还分别将u和v存储在变量matu和matv中。通过matu乘以diag乘以 t(matv)来看看你得到了什么。 
    （这最后一个表达式代表R中matv的转置）。回想一下，在R矩阵中，乘法运算要求使用运算符％*％。
  CorrectAnswer: matu %*% diag %*% t(matv)
  AnswerTests: omnitest(correctExpr='matu %*% diag %*% t(matv)')
  Hint: 在命令提示符处输入matu％*％diag％*％t（matv）.

- Class: text
  Output: 所以我们确实得到了mat的分解。请注意，这种类型的分解不是唯一的。

- Class: text
  Output: 现在我们来谈谈PCA，主成分分析（Principal Component Analysis），“一种简单的非参数方法，用于从混乱的数据集中提取相关信息。
    我们在这里引用了一个关于这个主题的非常好的简明论文，可以在http://arxiv.org/pdf/1404.1100.pdf找到。 Google Research的Jonathon Shlens的论文被称为“主成分分析教程”。

- Class: text
  Output: 基本上，PCA是一种将高维数据集减少到其基本要素（而不是丢失信息）并解释数据可变性的方法。我们不会在这里进入数学细节
   （R有执行PCA的功能），但是您应该知道SVD和PCA密切相关

- Class: cmd_question
  Output:  现在我们将演示这个。首先，我们必须扩展我们简单的示例数据矩阵mat。这意味着我们从每个元素中减去列平均值，并将结果除以列标准差。
    当然R有一个函数scale,能做到这些。运行svd(scale(mat))。
  CorrectAnswer: svd(scale(mat))
  AnswerTests: omnitest(correctExpr='svd(scale(mat))')
  Hint: 在命令提示符处输入svd（scale（mat））。

- Class: cmd_question
  Output: 现在运行R程序prcomp(scale(mat))。这会给你mat的主要组成部分。看他们是否看起来很熟悉。
  CorrectAnswer: prcomp(scale(mat))
  AnswerTests: omnitest(correctExpr='prcomp(scale(mat))')
  Hint: 在命令提示符下输入prcomp（scale（mat））。

- Class: text
  Output: 请注意，prcomp输出的Rotation组件中显示的缩放矩阵的主要成分是V列，右奇异值。因此，缩放矩阵的PCA产生相同缩放矩阵的V矩阵（右奇异向量）。

- Class: text
  Output: 现在我们介绍理论，让我们回到更大的随机数据矩阵，我们为coinflips选择的某些行添加了固定模式。该模式有效地改变了行和列的均值。

- Class: figure
  Output: 下面的图片显示了PCA和SVD之间的关系。我们绘制了10个点（5个在左下角一起被挤压）。 x坐标是第一个主成分（prcomp的输出）的元素，
    y坐标是V的第一列的元素，即第一个右奇异向量（从运行svd获得）。我们看到，所有的点都位于由方程y = x表示的45度线上。所以V的第一列是我们较大的数据矩阵的第一个主要成分。
  Figure: showRel.R
  FigureType: new

- Class: cmd_question
  Output: 为了证明我们没有这样做，我们已经在dataMatrix上运行了svd，并将结果存储在对象svd1中。这有三个组件，d，u和v。现在看V的第一列。
    它可以通过使用svd1$v [，1]表示法来查看。
  CorrectAnswer: svd1$v[,1]
  AnswerTests: omnitest(correctExpr='svd1$v[,1]')
  Hint: 在命令提示符下输入svd1$v[，1]。

- Class: text
  Output: 看看这些值如何对应绘图？其中五个条目稍微在点（-0.4，-0.4）的左边，另外两个是负的（在（0,0）的左边），
    三个是正的(在(0,0）的右边))

- Class: figure
  Output: 这里我们再次显示左侧的聚类数据矩阵。在它旁边，我们绘制了与缩放数据矩阵相关联的U矩阵的第一列。这是第一个LEFT奇异向量，
    它与聚类数据的ROW平均值相关联。你可以看到顶部24（约-0.2）行和底部16（约0.2）之间的清晰分隔。我们不显示它们，但请注意，
    U的其他列没有如此清楚地显示这种模式。
  Figure: showUV.R
  FigureType: new

- Class: text
  Output: 最右边的显示器显示与缩放和聚集的数据矩阵相关联的V矩阵的第一列。这是第一个RIGHT奇异向量，它与聚类数据的COLUMN平均值相关联。
    您可以看到左列5列之间的清晰分隔（在-0.1和0.1之间），右边5列表示（均低于-0.4）。与左边的奇异向量一样，
    V的其他列也没有像第一个那样明确地显示出这个模式。

- Class: text
  Output: 所以奇异值分解自动拾取这些模式，行列均值的差异

- Class: cmd_question
  Output: 为什么U和V矩阵的第一列如此特殊？当然，SVD的D矩阵解释了这个现象。这是SVD的一个方面，称为方差解释。回想一下，
    D是在数据矩阵的SVD表示中夹在U和V ^ t之间的对角矩阵。 D的对角元素值就像U和V列的权重，这些都是数据变化的原因。
    他们按照从高到低的顺序排列。现在看看这些对角线条目。回想一下，它们存储在svd1$d中
  CorrectAnswer: svd1$d
  AnswerTests: omnitest(correctExpr='svd1$d')
  Hint: 在命令提示符下输入svd1$d

- Class: figure
  Output: 这是这些值的显示（在左边）。第一个（12.46）比其他的要大得多。由于我们没有指定任何单位，在右侧我们绘制了每个条目所代表的方差比例。
    我们看到第一个元素占数据差异的大约40％。这就解释了为什么U和V矩阵的第一列分别显示了行列均值的独特模式如此清晰。
  Figure: showVar.R
  FigureType: new

- Class: cmd_question
  Output:  现在我们将向您展示SVD如何解释变化的另一个简单例子。我们创建了一个40×10的矩阵constantMatrix。
    以constantMatrix为参数使用R函数head查看顶部行。
  CorrectAnswer: head(constantMatrix)
  AnswerTests: omnitest(correctExpr='head(constantMatrix)')
  Hint: 在命令提示符下输入head（constantMatrix）。

- Class: cmd_question
  Output: 其余的行看起来也像这样，你可以看到左边5列全是0，右边5列全是1。我们用constantMatrix作为参数运行svd，并将结果存储在svd2中。
    现在看看svd2的对角线分量d。 
  CorrectAnswer: svd2$d
  AnswerTests: omnitest(correctExpr='svd2$d')
  Hint: 在命令提示符下输入svd2$d

- Class: mult_question
  Output: 哪个索引保存了svd2$d的最大元素？
  AnswerChoices:  9; 1; 10; 5
  CorrectAnswer:  1
  AnswerTests: omnitest(correctVal='1')
  Hint: 哪个选项有正确的指数？请注意，每一项都以科学记数法给出，其中xey表示x * 10 ^ y。

- Class: figure
  Output: 所以第一个输入远远地支配着其他输入。这里左边的图片显示了constantMatrix的热图。你可以看到左边的列和右边的列是不同的。
    中间的曲线图显示了矩阵奇异值的值，即作为svd2$d项的对角线元素。其中9个是0，第一个是稍高于14.第三个图表显示了每个对角线元素代表的总比例。 
  Figure: showSimple.R
  FigureType: new
     
- Class: mult_question
  Output: 根据图，第一个对角线元素占总变差的百分比是多少？
  AnswerChoices:  100%; 90%; 50%; 0%
  CorrectAnswer:  100%
  AnswerTests: omnitest(correctVal='100%')
  Hint: 第一个元素是1.0。 1.0表示的百分比是多少？

- Class: text
  Output: 那么这是什么意思？基本上数据是一维的。只有一条信息，即一个条目所在的列，决定了它的值。

- Class: figure
  Output: 现在让我们回到我们的随机的40乘10的数据矩阵，并考虑一个稍微复杂的例子，在这个例子中我们添加了2个模式。
    再次，我们将选择使用coinflips调整哪些行。具体来说，对于40行中的每一行，我们将翻转2个硬币。如果第一个coinflip是头，
    我们将在该行右侧5列中的每个元素添加5，如果第二个coinflip是头，我们将添加5到该行的偶数列。 
  Figure: twoPatts.R
  FigureType: new
    
- Class: figure
  Output: 所以这里是左侧缩放数据矩阵的图像。我们可以看到两种模式，即左侧5列和右侧5列之间的明显差异，而且还可以看到两列之间的交替模式。
    其他图显示添加到受影响的行中的真实模式。中间的图表显示了左右列之间的真实差异，而最右边的图表显示了奇数列和偶数列之间的真实差异。
  Figure: showTrue.R
  FigureType: new

- Class: text
  Output: 问题是，“我们的分析能否仅仅从数据中检测出这些模式？让我们来看看SVD显示的。既然我们对列上的模式感兴趣，
    我们先看看右边奇异向量前面两列（V的列），看看它们是否显示出模式的任何证据。

- Class: figure
  Output: 这里我们看到在数据矩阵的图像旁边绘制了2个右奇异向量。中间的图表显示V的第一列，最右边的图表显示v第二列。
    中间的图表显示最后5列比前5列有更高的数据项。这个符合或者至少暗示我们添加的第一个模式，其影响了矩阵的最后5列。
    最右边的图形显示V的第二列的看起来更随机。不过，仔细检查后可以看出，当你从左到右移动时，数据项会交替或反复上下。
    这符合我们添加的第二个模式，其中仅影响选定行的偶数列。
  Figure: showVs.R
  FigureType: new

- Class: cmd_question
  Output:  要更仔细地查看，请查看v组件的前2列。我们将SVD输出存储在svd对象svd2中 
  CorrectAnswer: svd2$v[,1:2]
  AnswerTests: ANY_of_exprs('svd2$v[,1:2]','svd2$v[,c(1,2)]','svd2$v[,c(1:2)]')
  Hint: 在命令提示符下输入svd2$v [，1：2]。

- Class: figure
  Output: 并排看到2列，我们看到两列中的值交替增加和减少。然而，我们知道要寻找这种模式，所以很可能，如果您不知道是否有这种模式，
    您可能没有注意到这种模式。这个例子是为了告诉你很难看到模式，甚至是简单的模式。
  Figure: clearPlot.R

- Class: cmd_question
  Output:  现在看看由svd产生的对角矩阵d。回想一下，我们将这个输出存储在svd对象svd2中。
  CorrectAnswer: svd2$d
  AnswerTests: omnitest(correctExpr='svd2$d')
  Hint: 在命令提示符下输入svd2$d。

- Class: figure
  Output:  我们看到，第一个因素14.55主导了其他因素。这是d的这些对角线元素的图。左边显示数字条目，右边显示每个条目解释的差异百分比。 
  Figure: showDvar.R
  FigureType: new

- Class: mult_question
  Output: 根据图表，第二个元素所占的方差有多少？
  AnswerChoices:  18%; 53%; 11%; .1% 
  CorrectAnswer: 18%
  AnswerTests: omnitest(correctVal='18%')
  Hint: 第二点落在右侧的图表上的高度是多少？

- Class: text 
  Output: 因此，第一个显示矩阵左右两半之间差异的元素约占矩阵变化的50％，第二个元素拾取交替图形占方差的18％。其余元素占变化的较小百分比。
    这表明第一种模式比第二种模式强得多。而且这两种模式彼此混淆，所以他们很难分离和看清楚。这是真实数据经常发生的情况。


- Class: text 
  Output: 现在你可能确信SVD和PCA作为分析工具是非常酷和有用的，但是你应该知道的一个问题是它们不能处理MISSING数据。
    如果矩阵中的任何数据丢失，它们都不会工作。 （如果你尝试的话，你会得到来自R的红色的错误消息。）丢失数据并不罕见，
    幸运的是我们有办法解决这个问题。我们刚刚提到的一个就是所谓的数据输入。

- Class: text
  Output:  这使用k个最近的邻居来计算一个值来代替丢失的数据。你可能想要指定一个整数k，它指出你想要平均多少个邻居来创建这个替换值。
    bioconductor软件包（http://bioconductor.org）有一个impute软件包，您可以用来填写缺失的数据。其中一个具体的功能是impute.knn。

- Class: text
  Output: 现在我们将继续讨论奇异值分解和主成分分析以及它们如何用作数据压缩技术的最后一个例子。

- Class: figure
  Output: 考虑显示一张脸的这个低分辨率图像文件。我们将使用SVD来查看前几个组件如何包含文件中的大部分信息，以便存储巨大的矩阵可能不是必需的。
  Figure: showFace.R
  FigureType: new

- Class: cmd_question
  Output:  图像数据存储在矩阵faceData中。在faceData上运行R命令dim，看看它有多大。
  CorrectAnswer: dim(faceData)
  AnswerTests: omnitest(correctExpr='dim(faceData)')
  Hint: 在命令提示符下输入dim（faceData）。

- Class: figure
  Output: 所以这不是一个大的文件，但我们想告诉你如何使用你在本课中学到的东西。我们已经完成了SVD并将其存储在svd1对象中。
    下面是解释的方差图。
  Figure: showFaceSVD.R
  FigureType: new

- Class: mult_question
  Output: 根据图解方差的百分比,多大比例是由第一个奇异值解释的吗？
  AnswerChoices:  23; 15; 40; 100
  CorrectAnswer: 40
  AnswerTests: omnitest(correctVal='40')
  Hint: 第一个（最左边的）点落在图形的什么高度？

- Class: text
  Output: 因此数据矩阵中40％的变化由第一个分量来解释，22％由第二个分量来解释，依此类推。看起来大部分的变化都包含在前10个组件中。
    我们怎样才能检查出来？我们可以尝试使用少数几个组件来创建一个近似的图像吗？

- Class: text
  Output: 回想一下，数据矩阵X是3个矩阵的乘积，即X = UDV ^ t。这些正是你在矩阵X上运行svd时得到的。 

- Class: text
  Output: 假设我们创建了这些片段的乘积，比如说U和V的第一列和D的第一个元素。U的第一列可以被解释为一个32乘1的矩阵
    （记得faceData是一个32×32矩阵），所以我们可以乘以D的第一个元素，一个1乘1的矩阵，并得到一个32乘1的矩阵结果。
     我们可以乘以第一个主成分V的第一列的转置。 （为了正确地进行矩阵乘法，我们必须使用V的列的转置来使它成为1乘32的矩阵。）

- Class: text
  Output: 理论上我们是这么做的，但是在R中只使用d中的一个元素意味着它是一个常数。所以我们必须用％*％运算符来算矩阵乘法和
    用常数乘法运算符*来执行与常数（svd1 $ d [1]）的乘法运算。

- Class: cmd_question
  Output: 现在试试这个，并把结果放在变量a1中。回想一下，svd1 $ u，svd1 $ d和svd1 $ v包含您需要的所有信息。注意，由于R的特性，
    如果你首先用*运算符进行标量乘法（在％*％运算符矩阵相乘之前），你必须把2个参数（svd1$u[，1]和svd1$d[1])括在括号里。
  CorrectAnswer: a1 <- svd1$u[,1] %*% t(svd1$v[,1]) * svd1$d[1]
  AnswerTests: expr_creates_var("a1"); ANY_of_exprs('a1 <- svd1$u[,1] %*% t(svd1$v[,1]) * svd1$d[1]','a1 <- (svd1$d[1] * svd1$u[,1]) %*% t(svd1$v[,1])','a1 <- (svd1$u[,1] * svd1$d[1]) %*% t(svd1$v[,1])')
  Hint: 输入a1<- svd1$u[，1]*svd1$d [1]％*％t(svd1$v[，1])或a1<- svd1$u[，1]％*％t（svd1$v [，1])*svd1$d[1]。

- Class: cmd_question
  Output:   现在把它看作一个图像。我们为你写了一个名为myImage的函数，它只接受一个参数，一个数据矩阵用R函数image显示。
    现在用a1作为参数运行它。
  CorrectAnswer: myImage(a1)
  AnswerTests: omnitest(correctExpr='myImage(a1)')
  Hint: 在命令提示符处输入myImage（a1）

- Class: text
  Output: 看起来可能不多，但这是一个好的开始。现在我们将尝试相同的实验，但是这次我们将使用3个SVD项中的每一个的2个元素。

- Class: cmd_question
  Output:  创建矩阵a2作为svd1$u的前2列，使用svd1$d的前2个元素的对角矩阵以及svd1$v的前2列的转置。由于所有被乘数都是矩阵，
    所以只能使用运算符％*％，而不需要括号。另外，您必须使用与svd1$d [1：2]作为唯一参数的R函数diag来创建适当的对角矩阵。
    请记住，矩阵乘法是不可交换的，所以你必须把被乘数放在正确的顺序。在指定列时，请使用1：2表示法，而不要使用c（m：n），即连接函数。
  CorrectAnswer: a2 <- svd1$u[,1:2] %*%  diag(svd1$d[1:2])  %*% t(svd1$v[,1:2]) 
  AnswerTests: expr_creates_var("a2"); omnitest(correctExpr='a2 <- svd1$u[,1:2] %*%  diag(svd1$d[1:2])  %*% t(svd1$v[,1:2])')
  Hint: 在命令提示符处输入a2 <- svd1 $ u [，1：2]％*％diag（svd1 $ d [1：2]）％*％t（svd1 $ v [，1：2]）

- Class: cmd_question
  Output:  再次使用myImage查看a2如何显示。
  CorrectAnswer: myImage(a2)
  AnswerTests: omnitest(correctExpr='myImage(a2)')
  Hint: 在命令提示符处输入myImage（a2）。

- Class: cmd_question
  Output: 我们开始看到更多的细节，也许如果你眯起眼睛，你会看到一个鬼脸。现在让我们看看使用5个组件的图像结果。
    从我们的方差图解释5个成分覆盖了相当大的变化百分比。为了保存输入，使用向上箭头调用创建a2的命令，并用调用myImage来替换a2和赋值箭头，
    并将三次出现的2更改为5。
  CorrectAnswer: myImage(svd1$u[,1:5] %*%  diag(svd1$d[1:5])  %*% t(svd1$v[,1:5]))
  AnswerTests:  omnitest(correctExpr='myImage(svd1$u[,1:5] %*%  diag(svd1$d[1:5])  %*% t(svd1$v[,1:5]))')
  Hint: 在命令提示符处键入myImage（svd1 $ u [，1：5]％* diag（svd1 $ d [1：5]）％*％t（svd1 $ v [，1：5]）））。

- Class: cmd_question
  Output: 当然好多了。很明显，一张脸上出现的眼睛，鼻子，耳朵和嘴巴都可以辨认出来。再次使用向上箭头调用最后一个命令
    （使用矩阵乘积参数调用myImage）并将5更改为10。我们将看到这个图像的外观。
  CorrectAnswer: myImage(svd1$u[,1:10] %*%  diag(svd1$d[1:10])  %*% t(svd1$v[,1:10]))
  AnswerTests:  omnitest(correctExpr='myImage(svd1$u[,1:10] %*%  diag(svd1$d[1:10])  %*% t(svd1$v[,1:10]))')
  Hint: 在命令提示符处键入myImage（svd1 $ u [，1：10]％* diag（svd1 $ d [1:10]）％*％t（svd1 $ v [，1：10]）））。

- Class: text
  Output: 现在已经非常接近低分辨率的原始图像，但是您可以看到，10个组件确实捕捉了图像的本质。奇异值分解是一种很好的方式来近似数据，
    而不必存储很多。

- Class: text
  Output: 首先，在降维缩小尺寸时，您必须注意测量不同变量的尺度，并确保所有数据都保持一致。换句话说，数据的规模很重要。
    其次，正如我们在简单的2样式例子中看到的，主成分和奇异值可能会混合真实的模式，因此找到并分离出真实的模式需要一些探究工作。
    现在让我们快速回顾一下。

- Class: mult_question
  Output: 以下哪个陈述至少捕捉了降维的本质？
  AnswerChoices:  find the needle in the haystack; see the forest through the trees; separate the wheat from the chaff; a face that could launch a 1000 ships
  CorrectAnswer: a face that could launch a 1000 ships
  AnswerTests: omnitest(correctVal='a face that could launch a 1000 ships')
  Hint: 哪一种选择不能处理有值和无值之间挑剔的差异。

- Class: mult_question
  Output: 矩阵X具有奇异值分解UDV ^ t。 X的主要组成部分是？
  AnswerChoices:  the columns of U; the rows of U; the columns of V; the rows of V
  CorrectAnswer: the columns of V
  AnswerTests: omnitest(correctVal='the columns of V')
  Hint: 回想一下在同一个缩放矩阵上运行prcomp和svd的简单示例，并且看到V的列与prcomp输出的旋转相匹配。

- Class: mult_question
  Output: 矩阵X具有奇异值分解UDV ^ t。 X的奇异值在哪里？
  AnswerChoices:  the columns of U; the columns of D; the columns of V; the diagonal elements of D; 
  CorrectAnswer: the diagonal elements of D
  AnswerTests: omnitest(correctVal='the diagonal elements of D')
  Hint: 回想一下，U和V给了我们向量，D给了我们值。

- Class: mult_question
  Output: 对还是错？ PCA和SVD是完全不相关的。
  AnswerChoices:  False; True
  CorrectAnswer: False
  AnswerTests: omnitest(correctVal='False')
  Hint: 回想一下主要组件及其与V的关系的问题

- Class: mult_question
  Output: 对还是错？ D给出矩阵的奇异值按照权重的递减顺序。
  AnswerChoices:  True; False
  CorrectAnswer: True
  AnswerTests: omnitest(correctVal='True')
  Hint: 回想一下，第一个值是数据变化的最高百分比。

- Class: mult_question
  Output: 确定将这次练习的结果提交吗?
  CorrectAnswer: NULL
  AnswerChoices: Yes;No
  AnswerTests: post_on_demand()
  Hint: ""

- Class: text
  Output: 恭喜!完成了数据降维的学习 
